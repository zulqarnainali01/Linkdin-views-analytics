{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30664,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# LinkedIn Views Analytics üîç\n\nLinkedIn lacks comprehensive content analytics, only providing insights on individual posts.\n\nBut what if we crave an overview of our posts' performance (likes, views, comments) over the past month?\n\nSolution? A Python program to visualize trends in post views over recent days. üìä Here's a peek at the results:\n\n[LinkedIn Views Analytics Notebook](https://www.kaggle.com/code/zulqarnainalipk/linkediln-views-analytics/notebook)\n\n---\n\n## Table of Contents\n\n- [Introduction](#introduction)\n- [Solution Overview](#solution-overview)\n- [How to Use](#how-to-use)\n- [Contributing](#contributing)\n- [Feedback](#feedback)\n\n## Introduction\n\nLinkedIn provides limited content analytics, focusing primarily on individual post metrics. However, users often desire a broader perspective on their posts' performance, encompassing metrics like likes, views, and comments over a longer period. This README introduces a Python program designed to address this need by visualizing trends in post views over recent days.\n\n## Solution Overview\n\nThis Python program utilizes Selenium, a portable framework for testing web applications, to navigate LinkedIn and extract relevant data. By analyzing the views of posts over time, users can gain insights into their content's performance trends.\n\n## How to Use\n\nTo utilize this program effectively, follow these steps:\n\n1. **Install Dependencies:** Ensure you have Python installed on your system along with the necessary libraries, particularly Selenium.\n   \n2. **Run the Program:** Execute the Python script provided in the notebook or download and run it locally.\n\n3. **Input LinkedIn Credentials:** Provide your LinkedIn username and password when prompted to access the desired data.\n\n4. **Review Results:** Once the program completes its execution, review the generated visualizations to analyze post view trends.\n\n## Contributing\n\nContributions to enhance the functionality or usability of this program are welcome! Please fork the repository, make your changes, and submit a pull request. Ensure your code adheres to best practices and includes appropriate documentation.\n\n## Feedback\n\nYour feedback is essential for the continuous improvement of this project. If you have any comments, suggestions, or encounter any issues, please don't hesitate to reach out. You can contact the project owner via email at [zulqar445ali@gmail.com](mailto:zulqar445ali@gmail.com).","metadata":{}},{"cell_type":"markdown","source":"üîß **1. Installing Selenium:**\nTo begin, I install Selenium, a powerful tool for automating web testing tasks.\n\nü§î **What's Selenium?**\nSelenium is a versatile framework designed for testing web applications. It supports various programming languages, including Python.\n\nüï∏Ô∏è **Key Features:**\n- **Cross-Language Compatibility:** Selenium supports multiple programming languages, making it accessible for developers.\n- **Browser Navigation:** With Selenium, developers can navigate through web browsers like Google Chrome (or others, but here we'll focus on Chrome).\n- **Python Integration:** Selenium provides a Python library equipped with methods tailored for web automation tasks.","metadata":{}},{"cell_type":"code","source":"!pip install selenium","metadata":{"execution":{"iopub.status.busy":"2024-03-01T11:05:10.432809Z","iopub.execute_input":"2024-03-01T11:05:10.433480Z","iopub.status.idle":"2024-03-01T11:05:27.137790Z","shell.execute_reply.started":"2024-03-01T11:05:10.433445Z","shell.execute_reply":"2024-03-01T11:05:27.136705Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting selenium\n  Downloading selenium-4.18.1-py3-none-any.whl.metadata (6.9 kB)\nRequirement already satisfied: urllib3<3,>=1.26 in /opt/conda/lib/python3.10/site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.26.18)\nCollecting trio~=0.17 (from selenium)\n  Downloading trio-0.24.0-py3-none-any.whl.metadata (4.9 kB)\nCollecting trio-websocket~=0.9 (from selenium)\n  Downloading trio_websocket-0.11.1-py3-none-any.whl.metadata (4.7 kB)\nRequirement already satisfied: certifi>=2021.10.8 in /opt/conda/lib/python3.10/site-packages (from selenium) (2024.2.2)\nRequirement already satisfied: typing_extensions>=4.9.0 in /opt/conda/lib/python3.10/site-packages (from selenium) (4.9.0)\nRequirement already satisfied: attrs>=20.1.0 in /opt/conda/lib/python3.10/site-packages (from trio~=0.17->selenium) (23.2.0)\nCollecting sortedcontainers (from trio~=0.17->selenium)\n  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)\nRequirement already satisfied: idna in /opt/conda/lib/python3.10/site-packages (from trio~=0.17->selenium) (3.6)\nCollecting outcome (from trio~=0.17->selenium)\n  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl.metadata (2.6 kB)\nRequirement already satisfied: sniffio>=1.3.0 in /opt/conda/lib/python3.10/site-packages (from trio~=0.17->selenium) (1.3.0)\nRequirement already satisfied: exceptiongroup in /opt/conda/lib/python3.10/site-packages (from trio~=0.17->selenium) (1.2.0)\nCollecting wsproto>=0.14 (from trio-websocket~=0.9->selenium)\n  Downloading wsproto-1.2.0-py3-none-any.whl.metadata (5.6 kB)\nRequirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in /opt/conda/lib/python3.10/site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\nRequirement already satisfied: h11<1,>=0.9.0 in /opt/conda/lib/python3.10/site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\nDownloading selenium-4.18.1-py3-none-any.whl (10.0 MB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m53.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading trio-0.24.0-py3-none-any.whl (460 kB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m460.2/460.2 kB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading trio_websocket-0.11.1-py3-none-any.whl (17 kB)\nDownloading wsproto-1.2.0-py3-none-any.whl (24 kB)\nDownloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\nDownloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\nInstalling collected packages: sortedcontainers, wsproto, outcome, trio, trio-websocket, selenium\nSuccessfully installed outcome-1.3.0.post0 selenium-4.18.1 sortedcontainers-2.4.0 trio-0.24.0 trio-websocket-0.11.1 wsproto-1.2.0\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## import Packages for Managing Web Scraping","metadata":{}},{"cell_type":"code","source":"#importing packages for managing web scrapping\nfrom selenium import webdriver","metadata":{"execution":{"iopub.status.busy":"2024-03-01T11:05:27.142363Z","iopub.execute_input":"2024-03-01T11:05:27.142722Z","iopub.status.idle":"2024-03-01T11:05:27.219724Z","shell.execute_reply.started":"2024-03-01T11:05:27.142689Z","shell.execute_reply":"2024-03-01T11:05:27.218624Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"!pip install bs4","metadata":{"execution":{"iopub.status.busy":"2024-03-01T11:05:27.220863Z","iopub.execute_input":"2024-03-01T11:05:27.221396Z","iopub.status.idle":"2024-03-01T11:05:39.324113Z","shell.execute_reply.started":"2024-03-01T11:05:27.221368Z","shell.execute_reply":"2024-03-01T11:05:39.322888Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Collecting bs4\n  Downloading bs4-0.0.2-py2.py3-none-any.whl.metadata (411 bytes)\nRequirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.10/site-packages (from bs4) (4.12.2)\nRequirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4->bs4) (2.5)\nDownloading bs4-0.0.2-py2.py3-none-any.whl (1.2 kB)\nInstalling collected packages: bs4\nSuccessfully installed bs4-0.0.2\n","output_type":"stream"}]},{"cell_type":"code","source":"from bs4 import BeautifulSoup\nimport re\nimport time","metadata":{"execution":{"iopub.status.busy":"2024-03-01T11:05:39.326962Z","iopub.execute_input":"2024-03-01T11:05:39.327358Z","iopub.status.idle":"2024-03-01T11:05:39.548435Z","shell.execute_reply.started":"2024-03-01T11:05:39.327323Z","shell.execute_reply":"2024-03-01T11:05:39.547241Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"#request user input for LinkedIn username and password:\nprint(\"Please enter the exact LinkedIn username you use to login (email/phone?):\")\nusername_string = str(input()) \nprint()\nprint(\"Please enter the exact LinkedIn password:\")\npassword_string = str(input())\nprint()\nprint(\"Please enter your usernmae exactly how it appears in your profile link (after '/in') :\")\nlink_username = str(input())\nprint()\nprint(\"Please enter the number of the last posts you want to analyse:\")\nnumber_of_posts = int(input())","metadata":{"execution":{"iopub.status.busy":"2024-03-01T11:05:39.549990Z","iopub.execute_input":"2024-03-01T11:05:39.550639Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Please enter the exact LinkedIn username you use to login (email/phone?):\n","output_type":"stream"}]},{"cell_type":"code","source":"browser = webdriver.Chrome(\"chromedrivers.exe\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#open the LinkedIn login page and login under a specified account:\nbrowser.get('https://www.linkedin.com/login')\n#enter the specified information to login to LinkedIn:\nelementID = browser.find_element_by_id('username')\nelementID.send_keys(username_string)\nelementID = browser.find_element_by_id('password')\nelementID.send_keys(password_string)\nelementID.submit()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#open the recent post activity page of the LinkedIn user you specified:\nrecent_activity_link = \"https://www.linkedin.com/in/\" + link_username + \"-3456bb1b8/recent-activity/shares/\"\nbrowser.get(recent_activity_link)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Scrap posts stats","metadata":{}},{"cell_type":"code","source":"#calculate number of scrolls depending on the input\nnumber_of_scrolls = -(-number_of_posts // 5)  # 5 is LinkedIn's number of posts per scroll","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#we need a loop because we have a particular number of scrolls...\nviews = []\n\nSCROLL_PAUSE_TIME = 5","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get scroll height\nlast_height = browser.execute_script(\"return document.body.scrollHeight\")\n\nfor scroll in range(number_of_scrolls) : \n    # Scroll down to bottom\n    browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n    # Wait to load page\n    time.sleep(SCROLL_PAUSE_TIME)\n    # Calculate new scroll height and compare with last scroll height\n    new_height = browser.execute_script(\"return document.body.scrollHeight\")\n    if new_height == last_height:\n        break\n    last_height = new_height","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#query the contents (returns service reponse object with web contents, url headers, status and other):\nsrc = browser.page_source\n#beautiful soup instance:\nsoup = BeautifulSoup(src, features=\"lxml\")   #lxml","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### üîç Searching for Likes on LinkedIn\n\n1. **Locating \"Likes\" on the Page:**\n   To find the likes on LinkedIn, we'll search for \"span\" tags with specific attributes. You can do this by inspecting the page and identifying the relevant elements.\n\n2. **Identifying Relevant \"span\" Tags:**\n   Look for \"span\" tags with specific attributes that likely denote the likes on LinkedIn posts. These attributes can vary based on the structure of the page.\n\n3. **Converting Tags to Strings:**\n   Once we've located the relevant \"span\" tags, we'll convert them into strings. This step is crucial for extracting the desired information effectively.\n\n4. **Extracting Desired Tags from Soup Contents:**\n   Finally, we'll search for the specific tags (\"<stuff>\") within the soup contents. These tags likely contain the information we're looking for, such as the number of likes on LinkedIn posts.","metadata":{}},{"cell_type":"code","source":"likes_bs4tags = soup.find_all(\"span\", attrs = {\"class\" : \"v-align-middle social-details-social-counts__reactions-count\"})\n#converts a list of 1 string to int, appends to likes list\nfor tag in likes_bs4tags:\n    strtag = str(tag)\n    #the first argument in findall (below) is a regular expression (accounts for commas in the number)\n    list_of_matches = re.findall('[,0-9]+',strtag)\n    #converts the last element (string) in the list to int, appends to likes list\n    last_string = list_of_matches.pop()\n    without_comma = last_string.replace(',','')\n    likes_int = int(without_comma)\n    likes.append(likes_int)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#find VIEWS on LinkedIn\n#same concept here\nviews_bs4tags = soup.find_all(\"span\", attrs = {\"class\" : \"icon-and-text-container t-14 t-black--light t-normal\"})\nfor tag in views_bs4tags:\n    strtag = str(tag)\n    list_of_matches = re.findall('[,0-9]+',strtag)\n    last_string = list_of_matches.pop()\n    without_comma = last_string.replace(',','')\n    views_int = int(without_comma)\n    views.append(views_int)  \n    \nprint(views)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Visualization","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Reverse the lists\nviews.reverse()\n\n# Convert lists into pandas DataFrames\nviews_df = pd.DataFrame(views, columns =['Views'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get rid of the outliers\n#   remove data points if further than 3 standard deviations away...\nviews_df_no_outliers = views_df[np.abs(views_df-views_df.median()) <= (3*views_df.std())]\n\n#   replace NaN values (deleted outliers) with the median values\nviews_df_no_outliers['Views'].fillna((views_df_no_outliers['Views'].median()), inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('**************************')\nprint('********* VIEWS **********')\nprint('**************************')\ncoefficients_views, residuals_views, _, _, _ = np.polyfit(range(len(views_df_no_outliers)),views_df_no_outliers,1,full=True)\nmse_views = (residuals_views[0])/(len(views_df_no_outliers))\nnrmse_views = (np.sqrt(mse_views))/(views_df_no_outliers.max() - views_df_no_outliers.min())\nslope_views = coefficients_views[0]\nprint('Slope: ' + str(slope_views))\nprint('NRMSE Error: ' + str(nrmse_views))\nplt.plot(views_df_no_outliers)\nplt.plot([slope_views*x + coefficients_views[1] for x in range(len(views_df_no_outliers))])\nplt.title('LinkedIn Post Views for ' + link_username)\nplt.xlabel('Posts')\nplt.ylabel('Views')\nplt.savefig(link_username + '-linkedin-views-last-' + str(number_of_posts) + '-posts-GRAPH.png', dpi=600)\nplt.show()\nplt.clf()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Save dataframes as CSV files \nviews_df_no_outliers.to_csv(link_username + '-linkedin-views-last-' + str(number_of_posts) + '-posts.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Keep Exploring! üëÄ\n\nThank you for delving into this notebook! If you found it insightful or beneficial, I encourage you to explore more of my projects and contributions on my profile.\n\nüëâ [Visit my Profile](https://www.kaggle.com/zulqarnainalipk) üëà\n\n[GitHub](https://github.com/zulqarnainali01) | [LinkedIn](https://www.linkedin.com/in/zulqarnain-ali-a9867a273/)\n\n## Share Your Thoughts! üôè\n\nYour feedback is invaluable! Your insights and suggestions drive our ongoing improvement. If you have any comments, questions, or ideas to contribute, please feel free to reach out.\n\nüì¨ Contact me via email: [zulqar445ali@gmail.com](mailto:zulqar445ali@gmail.com)\n\nI extend my sincere gratitude for your time and engagement. Your support inspires us to create even more valuable content.","metadata":{}}]}